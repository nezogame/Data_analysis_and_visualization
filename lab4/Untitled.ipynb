{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ac981a-5f02-4f16-856a-06cacf17c05b",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc4efb84-759c-4529-b423-4cf8e1f5448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5be6f9-9453-460e-b67d-0f40caf3a786",
   "metadata": {},
   "source": [
    "## 1.Завантаження залежних та незалежних вибірок з текстових файлів. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f95aae76-15f9-4ddf-8606-ad4c7110bb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.6972</td>\n",
       "      <td>5.1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.6110</td>\n",
       "      <td>4.6356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0273</td>\n",
       "      <td>6.8693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.3691</td>\n",
       "      <td>5.9564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.8548</td>\n",
       "      <td>5.8500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x       y\n",
       "0  10.6972  5.1307\n",
       "1  12.6110  4.6356\n",
       "2  15.0273  6.8693\n",
       "3  10.3691  5.9564\n",
       "4   7.8548  5.8500"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data_lab4/dep/norm!=1.txt\"\n",
    "columns = ['x','y']\n",
    "df = pd.read_csv(path, delimiter=\" \", header=None, names=columns)\n",
    "path = \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992ab24f-0c00-4a8d-90eb-55cfdb107c5a",
   "metadata": {},
   "source": [
    "### check whether path contain depended"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2444f4-800d-45bb-97f3-95145a183e4e",
   "metadata": {},
   "source": [
    "## Creating class for calculation quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2e10ae4-6307-4246-becc-d2e1ed9f3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Коефіцієнти для формули\n",
    "C0 = 2.515_517\n",
    "C1 = 0.802_853\n",
    "C2 = 0.010_328\n",
    "D1 = 1.432_788\n",
    "D2 = 0.189_265_9\n",
    "D3 = 0.001_308\n",
    "\n",
    "class Quantile:\n",
    "    \n",
    "    @classmethod\n",
    "    def calculate_quantile(cls, p):\n",
    "        if p > 0.5:\n",
    "            t = np.sqrt(-2 * np.log(1 - p))\n",
    "            quantile = (t - ((C0 + C1 * t + C2 * t ** 2) / (1 + D1 * t + D2 * t ** 2 + D3 * t ** 3)))\n",
    "        else:\n",
    "            t = np.sqrt(-2 * np.log(p))\n",
    "            quantile = -(t - ((C0 + C1 * t + C2 * t ** 2) / (1 + D1 * t + D2 * t ** 2 + D3 * t ** 3)))\n",
    "\n",
    "        return quantile\n",
    "        \n",
    "    @staticmethod\n",
    "    def student_quantile(p, v):\n",
    "        up = Quantile.calculate_quantile(p)\n",
    "        tpv = up + (1 / v) * (1 / 4) * (up ** 3 + up) + (1 / v ** 2) * (1 / 96) * (\n",
    "            5 * up ** 5 + 16 * up ** 3 + 3 * up) + (1 / v ** 3) * (1 / 384) * (\n",
    "                  3 * up ** 7 + 19 * up ** 5 + 17 * up ** 3 - 15 * up) + (1 / v ** 4) * (1 / 92_160) * (\n",
    "                  79 * up ** 9 + 779 * up ** 7 + 1_482 * up ** 5 - 1_920 * up ** 3 - 945 * up)\n",
    "        return tpv\n",
    "    \n",
    "    @staticmethod\n",
    "    def fisher_quantile(p ,v1, v2):\n",
    "        up = Quantile.calculate_quantile(p)   \n",
    "\n",
    "        sigma = 1/v1 + 1/v2\n",
    "        delta = 1/v1 - 1/v2\n",
    "        \n",
    "        z = (up * np.sqrt(sigma / 2) -\n",
    "         (1 / 6) * delta * (up**2 + 2) +\n",
    "         np.sqrt(sigma / 2) * (sigma / 24 * (up**2 + 3 * up) + (1 / 72) * (delta**2 / sigma) * (up**3 + 11 * up)) -\n",
    "         (sigma * delta / 120) * (up**4 + 9 * up**2 + 8) +\n",
    "         (delta**3 / (3240 * sigma)) * (3 * up**4 + 7 * up**2 - 16) +\n",
    "         np.sqrt(sigma / 2) * (sigma**2 / 1920 * (up**5 + 20 * up**3 + 15 * up)) +\n",
    "         (delta**4 / 2880) * (up**5 + 44 * up**3 + 183 * up) +\n",
    "         (delta**5 / (155520 * sigma**2)) * (9 * up**5 + 284 * up**3 + 1513 * up)\n",
    "        )\n",
    "\n",
    "        return np.exp(2*z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b2140e-548d-4096-bf51-8799afdcf926",
   "metadata": {},
   "source": [
    "## Критерії перевірки однорідності двох залежних вибірок: критерії перевірки рівності дисперсій та середніх + критерій знакових рангів Вілкоксона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "038dd0cc-16e9-44ae-aad3-df71273725d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DependentSamples:\n",
    "    @classmethod\n",
    "    def create_thrird_sample(cls, df):\n",
    "        df['z'] = df['x']-df['y']\n",
    "\n",
    "        z_mean = np.mean(df['z'])\n",
    "        z_std = np.std(df['z'], ddof=1)\n",
    "       \n",
    "        return DependentSamples.calculate_t(len(df)-1, z_mean, z_std)\n",
    "\n",
    "    @classmethod\n",
    "    def calculate_t(cls, length, z_mean, z_std):\n",
    "        if z_mean==0 and z_std==0:\n",
    "            t=0\n",
    "        else:\n",
    "            t = z_mean*np.sqrt(length)/z_std\n",
    "        return DependentSamples.is_mean_equal(t, length-1)\n",
    "\n",
    "    @classmethod\n",
    "    def is_mean_equal(cls, t, n):\n",
    "        print('t equals: '+str(t))\n",
    "        print('Quantile: '+str(Quantile.student_quantile(1-0.05/2, n)))\n",
    "        return np.abs(t)<=Quantile.student_quantile(1-0.05/2, n)\n",
    "\n",
    "    # @classmethod\n",
    "    # def is_variances_equal(cls, t, n):\n",
    "    #     print('t equals: '+str(t))\n",
    "    #     print('Quantile: '+str(Quantile.student_quantile(1-0.05/2, n)))\n",
    "    #     return np.abs(t)<=Quantile.student_quantile(1-0.05/2, n)\n",
    "    \n",
    "    @classmethod\n",
    "    def calculate_statistic(cls, df):\n",
    "        squared_x_std = np.std(df['x'], ddof=1)**2\n",
    "        squared_y_std = np.std(df['y'], ddof=1)**2\n",
    "        if(squared_x_std>=squared_y_std):\n",
    "            f=squared_x_std/squared_y_std\n",
    "            v1 = df['x'].count() - 1\n",
    "            v2 = df['y'].count() - 1 \n",
    "        else:\n",
    "            f=squared_y_std/squared_x_std\n",
    "            v1 = df['y'].count() - 1 \n",
    "            v2 = df['x'].count() - 1\n",
    "        \n",
    "        #check is variances coincide\n",
    "        f_fisher = Quantile.fisher_quantile(0.95,v1,v2)\n",
    "        print('F:' +str(f))\n",
    "        print('F fisher:' +str(f_fisher))\n",
    "        return f<=f_fisher\n",
    "        \n",
    "    @staticmethod\n",
    "    def check_for_homogeneity(df):\n",
    "        mean_equal = DependentSamples.create_thrird_sample(df)\n",
    "        varians_equal = DependentSamples.calculate_statistic(df)\n",
    "        print('Is mean equals: '+str(mean_equal))\n",
    "        print('Is varians equals: '+str(varians_equal))\n",
    "\n",
    "    @staticmethod\n",
    "    def check_for_homogeneity(df):\n",
    "        mean_equal = DependentSamples.create_thrird_sample(df)\n",
    "        varians_equal = DependentSamples.calculate_statistic(df)\n",
    "        print('Is mean equals: '+str(mean_equal))\n",
    "        print('Is varians equals: '+str(varians_equal))\n",
    "        if mean_equal and varians_equal:\n",
    "            print('homogeneous sample')\n",
    "        else:\n",
    "            print('NOT homogeneous sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8615583-00e5-4182-b458-9ad02f6f5173",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "548b86f4-92cf-4b6b-8dc4-8296ef8cc3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t equals: 25.714023078404278\n",
      "Quantile: 1.9683892292999465\n",
      "F:4.734445461528674\n",
      "F fisher:1.2098984878687653\n",
      "Is mean equals: False\n",
      "Is varians equals: False\n",
      "NOT homogeneous sample\n"
     ]
    }
   ],
   "source": [
    "DependentSamples.check_for_homogeneity(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ef62bf-00b2-47f3-bf7e-efe43f647889",
   "metadata": {},
   "source": [
    "## Критерії перевірки однорідності двох незалежних вибірок: критерії перевірки рівності дисперсій та середніх + ранговий критерій, заданий індивідуальним варіантом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6a60d5f8-640d-422e-b63c-9e57fbf645b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndependentSamples:\n",
    "    @classmethod\n",
    "    def calculate_weighted_average_and_t(cls, df):\n",
    "        x_mean = np.mean(df['x'])\n",
    "        y_mean = np.mean(df['y'])\n",
    "        x_dispersion = np.std(df['x'], ddof=1)**2\n",
    "        y_dispersion = np.std(df['y'], ddof=1)**2\n",
    "        x_n =df['x'].count()\n",
    "        y_n =df['y'].count()\n",
    "\n",
    "        weighted_average = ((x_n-1)*x_dispersion+(y_n-1)*y_dispersion)/(x_n+y_n-2)\n",
    "        \n",
    "        t = (x_mean-y_mean)/(np.sqrt(weighted_average/x_n+weighted_average/y_n))\n",
    "        \n",
    "        print('weighted average: '+str(weighted_average))\n",
    "        print('t equals: '+str(t))\n",
    "        \n",
    "        return IndependentSamples.is_mean_equal(t, x_n+y_n-2)\n",
    "\n",
    "    @classmethod\n",
    "    def is_mean_equal(cls, t, v):\n",
    "        print('Quantile: '+str(Quantile.student_quantile(1-0.05/2, v)))\n",
    "        return np.abs(t)<=Quantile.student_quantile(1-0.05/2, v)\n",
    "\n",
    "    @classmethod\n",
    "    def calculate_criterion_with_welch_correction(cls, df):\n",
    "        x_mean = np.mean(df['x'])\n",
    "        y_mean = np.mean(df['y'])\n",
    "        x_dispersion = np.std(df['x'], ddof=1)**2\n",
    "        y_dispersion = np.std(df['y'], ddof=1)**2\n",
    "        x_n =df['x'].count()\n",
    "        y_n =df['y'].count()\n",
    "        \n",
    "        t = (x_mean-y_mean)/(np.sqrt(x_dispersion/x_n+y_dispersion/y_n))\n",
    "        \n",
    "        v = (x_dispersion/x_n+y_dispersion/y_n)**2*((1/(x_n-1)*(x_dispersion/x_n)**2)+(1/(y_n-1)*(y_dispersion/y_n)**2))**-1\n",
    "\n",
    "        print('v: '+str(v))\n",
    "        print('t equals: '+str(t))\n",
    "        \n",
    "        return IndependentSamples.is_mean_equal(t, v)\n",
    "\n",
    "    @classmethod\n",
    "    def claculate_rank_shift_criterion(cls, df, n1, n2):\n",
    "        v = sum(list(df))\n",
    "        ev = 1/2*n1*n2\n",
    "        dv = 1/12*n1*n2*(n1+n2+1)\n",
    "        u = (v-ev)/np.sqrt(dv)\n",
    "        print('v equals: '+str(v))\n",
    "        print('E{V} equals: '+str(ev))\n",
    "        print('D{V} equals: '+str(dv))\n",
    "        print('u equals: '+str(u))\n",
    "        quantile = Quantile.calculate_quantile(1-0.05/2)\n",
    "        print('Quantile: '+str(quantile))\n",
    "        return np.abs(u)<=quantile\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_for_homogeneity(df, varians_equal):\n",
    "\n",
    "        if varians_equal:\n",
    "            mean_equal = IndependentSamples.calculate_weighted_average_and_t(df)\n",
    "        else:\n",
    "            mean_equal = IndependentSamples.calculate_criterion_with_welch_correction(df)\n",
    "\n",
    "        print('Is mean equals: '+str(mean_equal))\n",
    "        print('Is varians equals: '+str(varians_equal))\n",
    "        if mean_equal and varians_equal:\n",
    "            print('homogeneous sample')\n",
    "        else:\n",
    "            print('NOT homogeneous sample')\n",
    "       \n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_rank_with_mann_whitney(df):\n",
    "        result = {}\n",
    "        for x_val in df['x']:\n",
    "            inversions = 0\n",
    "            for y_val in df['y']:\n",
    "                if y_val < x_val:\n",
    "                    inversions += 1\n",
    "                elif y_val == x_val:\n",
    "                    inversions += 0.5  # semi inversion\n",
    "            result[x_val] = inversions\n",
    "        shift_exist = IndependentSamples.claculate_rank_shift_criterion(result.values(), df['x'].count(), df['y'].count())\n",
    "        if shift_exist:\n",
    "            print('NO shift exist')\n",
    "        else:\n",
    "            print('shift exist')\n",
    "            \n",
    "        return shift_exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa98b64-5c9a-4e07-a132-40b270773ad0",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fd578ddd-4d5d-47ef-80bf-1116b86c6978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:4.734445461528674\n",
      "F fisher:1.2098984878687653\n",
      "v: 419.9140102725909\n",
      "t equals: 26.043869255210645\n",
      "Quantile: 1.9660608500811243\n",
      "Is mean equals: False\n",
      "Is varians equals: False\n",
      "NOT homogeneous sample\n",
      "None\n",
      "v equals: 83616.5\n",
      "E{V} equals: 45000.0\n",
      "D{V} equals: 4507500.0\n",
      "u equals: 18.188841619423197\n",
      "Quantile: 1.960392179315197\n",
      "shift exist\n"
     ]
    }
   ],
   "source": [
    "print(''+str(IndependentSamples.check_for_homogeneity(df, DependentSamples.calculate_statistic(df))))\n",
    "res = IndependentSamples.calculate_rank_with_mann_whitney(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb5292-2ec6-4b8c-9f80-49eed8c042c9",
   "metadata": {},
   "source": [
    "### Check wheather distribution normal or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1215a2e3-5da0-48b1-83ab-b7f9cff89c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "# Shapiro-Wilk test for 'x'\n",
    "statistic_x, p_value_x = stats.shapiro(df['x'])\n",
    "normal_x = p_value_x > alpha\n",
    "\n",
    "# Shapiro-Wilk test for 'y'\n",
    "statistic_y, p_value_y = stats.shapiro(df['y'])\n",
    "normal_y = p_value_y > alpha\n",
    "\n",
    "if normal_x and normal_y:\n",
    "    normal =True;\n",
    "else:\n",
    "    normal =False;\n",
    "\n",
    "print(normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6954a-457b-4005-84c9-5c7a3469a8a4",
   "metadata": {},
   "source": [
    "## Підрахунок і виведення у таблицю незсунених кількісних характеристики кожної виибірки, а також вибірки різниць у випадку залежних вибірок. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f89bbb-6b58-48d9-b276-419f5e5d16f0",
   "metadata": {},
   "source": [
    "### creating class for calculating a Quantitative Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "02df85ed-d902-4410-9fef-faa1eb8786f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantitativeCharacteristics:\n",
    "\n",
    "    def __init__(self,sample):\n",
    "        self.sample = sample\n",
    "        self.characteristic_fields_map = [\"Mean\", \"Median\", \"Std\", \"Skewness\", \"Kurtosis\", \"Min\", \"Max\"]\n",
    "        self.characteristic_table_dictionary = dict()\n",
    "        self.mean = None\n",
    "        self.std_deviation = None\n",
    "        self.a = None\n",
    "        self.e = None\n",
    "        self.sa = None\n",
    "        self.se = None\n",
    "    \n",
    "    def add_to_dictionary(self, column_name, column_data):\n",
    "        self.characteristic_table_dictionary.update({column_name: column_data})\n",
    "\n",
    "    def display(self):\n",
    "        self.add_characteristics()\n",
    "        return self.characteristic_table_dictionary\n",
    "\n",
    "    def add_characteristics(self):\n",
    "        estimation = self.calculate_estimation()\n",
    "        self.add_to_dictionary(\"Characteristic\", self.characteristic_fields_map)\n",
    "        self.add_to_dictionary(\"Estimation\", estimation.keys())\n",
    "        self.add_to_dictionary(\"SEM\", estimation.values())\n",
    "        confidence_intervals = self.calculate_confidence_interval(estimation)\n",
    "        self.add_to_dictionary(\"95% Confidence Interval\", confidence_intervals)\n",
    "\n",
    "    def calculate_confidence_interval(self, estimation: dict):\n",
    "        confidence_interval = list(range(0, 7))\n",
    "        median_conf_interval = self.calculate_median_confidence_interval(list(estimation.keys())[1])\n",
    "        confidence_interval[1] = f\"[{median_conf_interval[0]}; {median_conf_interval[1]}]\"\n",
    "        confidence_interval[5] = \"───\"\n",
    "        confidence_interval[6] = \"───\"\n",
    "\n",
    "        v = len(self.sample) - 1\n",
    "        student_quantile = Quantile.student_quantile(0.95, v)\n",
    "        print(\"student_quantile: \" + str(student_quantile))\n",
    "        i = 0\n",
    "        for key in estimation.keys():\n",
    "            if (estimation.get(key) == \"───\"):\n",
    "                i = i + 1\n",
    "                continue\n",
    "            upper_bound = round(key - student_quantile * estimation.get(key), 4)\n",
    "            lower_bound = round(key + student_quantile * estimation.get(key), 4)\n",
    "            confidence_interval[i] = f\"[{upper_bound}; {lower_bound}]\"\n",
    "\n",
    "            i = i + 1\n",
    "\n",
    "        return confidence_interval\n",
    "\n",
    "    def calculate_median_confidence_interval(self, median):\n",
    "        num_samples = 1000\n",
    "\n",
    "        bootstrap_samples = [np.random.choice(self.sample, size=len(self.sample), replace=True) for _ in\n",
    "                             range(num_samples)]\n",
    "\n",
    "        bootstrap_medians = np.median(bootstrap_samples, axis=1)\n",
    "\n",
    "        std_error_median = np.std(bootstrap_medians, ddof=1)\n",
    "        v = len(self.sample) - 1\n",
    "        student_quantile = Quantile.student_quantile(1 - 0.05 / 2, v)\n",
    "        lower_bound = round(median - student_quantile * std_error_median, 4)\n",
    "        upper_bound = round(median + student_quantile * std_error_median, 4)\n",
    "\n",
    "        return lower_bound, upper_bound\n",
    "\n",
    "    def calculate_normal_interval(self):\n",
    "        v = len(self.sample) - 1\n",
    "        student_quantile = Quantile.student_quantile(1 - 0.05 / 2, v)\n",
    "        lower_bound = round(self.mean - student_quantile * self.std_deviation, 4)\n",
    "        upper_bound = round(self.mean + student_quantile * self.std_deviation, 4)\n",
    "        return lower_bound, upper_bound\n",
    "\n",
    "    def calculate_estimation(self):\n",
    "        estimation_map = dict()\n",
    "        self.mean = round(np.mean(self.sample), 4)\n",
    "        median = round(np.median(self.sample), 4)\n",
    "        self.std_deviation = round(np.std(self.sample, ddof=1), 4)\n",
    "        self.a = round(stats.skew(self.sample), 4)\n",
    "        self.e = round(stats.kurtosis(self.sample), 4)\n",
    "        minimum = round(min(self.sample), 4)\n",
    "        maximum = round(max(self.sample), 4)\n",
    "\n",
    "        n_len = len(self.sample)\n",
    "        mean_std = round(self.std_deviation / np.sqrt(n_len), 4)\n",
    "        std_std_deviation = round(self.std_deviation / np.sqrt(2 * n_len), 4)\n",
    "        self.sa = round(np.sqrt(6 * n_len * (n_len - 1) / ((n_len - 2) * (n_len + 1) * (n_len + 3))), 4)\n",
    "        self.se = round(\n",
    "            np.sqrt(24 * n_len * (n_len - 1) ** 2 / ((n_len - 3) * (n_len - 2) * (n_len + 3) * (n_len + 5))), 4)\n",
    "\n",
    "        estimation_map[self.mean] = mean_std\n",
    "        estimation_map[median] = \"───\"\n",
    "        estimation_map[self.std_deviation] = std_std_deviation\n",
    "        estimation_map[self.a] = self.sa\n",
    "        estimation_map[self.e] = self.se\n",
    "        estimation_map[minimum] = \"───\"\n",
    "        estimation_map[maximum] = \"───\"\n",
    "        return estimation_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239f4909-3936-4da8-8e0c-9a21968c8c4d",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8d724d53-039f-4700-808b-16c7bae6cf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_quantile: 1.650323668219721\n",
      "  Characteristic  Estimation     SEM 95% Confidence Interval\n",
      "0           Mean     10.0984  0.1736       [9.8119; 10.3849]\n",
      "1         Median     10.1878     ───        [9.8176; 10.558]\n",
      "2            Std      3.0075  0.1228        [2.8048; 3.2102]\n",
      "3       Skewness      0.0207  0.1407       [-0.2115; 0.2529]\n",
      "4       Kurtosis     -0.1347  0.2805       [-0.5976; 0.3282]\n",
      "5            Min      2.6526     ───                     ───\n",
      "6            Max     20.3890     ───                     ───\n",
      "----------\n",
      "student_quantile: 1.650323668219721\n",
      "  Characteristic  Estimation     SEM 95% Confidence Interval\n",
      "0           Mean      5.1214  0.0798        [4.9897; 5.2531]\n",
      "1         Median      5.0903     ───        [4.8848; 5.2958]\n",
      "2            Std      1.3822  0.0564        [1.2891; 1.4753]\n",
      "3       Skewness      0.2429  0.1407        [0.0107; 0.4751]\n",
      "4       Kurtosis      0.5894  0.2805        [0.1265; 1.0523]\n",
      "5            Min      1.6105     ───                     ───\n",
      "6            Max     11.0000     ───                     ───\n"
     ]
    }
   ],
   "source": [
    "q_c1 = QuantitativeCharacteristics(df['x'])\n",
    "q_c2 = QuantitativeCharacteristics(df['y'])\n",
    "res1= pd.DataFrame(q_c1.display())\n",
    "print(res1)\n",
    "print('----------')\n",
    "res2=  pd.DataFrame(q_c2.display())\n",
    "print(res2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53585765-194f-40ad-8357-ecd2635e5a60",
   "metadata": {},
   "source": [
    "### Checking the equality of variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adbd3e3d-c61f-4105-aa41-64197d058b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for 1 column: 19.944359420289857\n",
      "Mean for 2 column: 0.5\n",
      "STD for 1 column: 62.469627554837615\n",
      "STD for 2 column: 0.2518248175182482\n"
     ]
    }
   ],
   "source": [
    "x_mean = np.mean(df['x'])\n",
    "y_mean = np.mean(df['y'])\n",
    "squared_x_std = np.std(df['x'], ddof=1)**2\n",
    "squared_y_std = np.std(df['y'], ddof=1)**2\n",
    "print(\"Mean for 1 column: \"+ str(x_mean))\n",
    "print(\"Mean for 2 column: \"+ str(y_mean))\n",
    "print(\"STD for 1 column: \"+ str(squared_x_std))\n",
    "print(\"STD for 2 column: \"+ str(squared_y_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5a0659-24df-4a89-a9dd-646dd5f36f64",
   "metadata": {},
   "source": [
    "#### Calculate P value with CDF(using student quantile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9667e626-1679-463a-b56b-5f14cd724b2e",
   "metadata": {},
   "source": [
    "### Calculate paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a56174-9399-4630-8bbf-8246b2261a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.325667428104424"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = df['x'].count() - 1\n",
    "v2 = df['y'].count() - 1 \n",
    "\n",
    "Quantile.fisher_quantile(0.95,v1,v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112834e7-0d08-4fd2-9bb0-da7db8ceabad",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = (squared_x_std/squared_y_std)\n",
    "if(normal):\n",
    "    2\n",
    "elif(f>1):\n",
    "    print(\"F equalse: \" + str(F))\n",
    "    2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
